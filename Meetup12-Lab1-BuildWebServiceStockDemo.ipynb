{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB1 - Model Operationalization & Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will create the artifacts and scripts to deploy the LSTM model into a webservice on Azure. The artifacts include the model files, and test scripts to validate your model can be used to predict future reliability of the engines based on the present operating characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# import the libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "from keras.models import model_from_json\n",
    "from urllib.request import urlretrieve\n",
    "import pandas\n",
    "\n",
    "import h5py\n",
    "\n",
    "# For creating the deployment schema file\n",
    "from azureml.api.schema.dataTypes import DataTypes\n",
    "from azureml.api.schema.sampleDefinition import SampleDefinition\n",
    "from azureml.api.realtime.services import generate_schema\n",
    "\n",
    "# For Azure blob storage access\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARE_ROOT = \"./stockdemo-model/\"\n",
    "\n",
    "# the model in json format\n",
    "LSTM_MODEL = SHARE_ROOT + 'modellstm.json'\n",
    "\n",
    "# the weights in h5\n",
    "MODEL_WEIGHTS = SHARE_ROOT + 'modellstm.h5'\n",
    "\n",
    "# and the schema file\n",
    "SCHEMA_FILE = SHARE_ROOT + 'service_schema.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the test data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"MSFT.csv\", index_col='Date')\n",
    "# Converting the index as date\n",
    "data.index = pandas.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Adj. Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>117.37</td>\n",
       "      <td>118.62</td>\n",
       "      <td>112.00</td>\n",
       "      <td>116.56</td>\n",
       "      <td>26614200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.066089</td>\n",
       "      <td>39.482146</td>\n",
       "      <td>37.278708</td>\n",
       "      <td>38.796484</td>\n",
       "      <td>53228400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>113.56</td>\n",
       "      <td>117.12</td>\n",
       "      <td>112.25</td>\n",
       "      <td>112.62</td>\n",
       "      <td>27059500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.797947</td>\n",
       "      <td>38.982878</td>\n",
       "      <td>37.361920</td>\n",
       "      <td>37.485073</td>\n",
       "      <td>54119000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>111.12</td>\n",
       "      <td>116.37</td>\n",
       "      <td>109.37</td>\n",
       "      <td>113.81</td>\n",
       "      <td>32029800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.985804</td>\n",
       "      <td>38.733244</td>\n",
       "      <td>36.403324</td>\n",
       "      <td>37.881159</td>\n",
       "      <td>64059600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>112.19</td>\n",
       "      <td>113.87</td>\n",
       "      <td>108.37</td>\n",
       "      <td>110.00</td>\n",
       "      <td>27488300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.341949</td>\n",
       "      <td>37.901130</td>\n",
       "      <td>36.070479</td>\n",
       "      <td>36.613017</td>\n",
       "      <td>54976600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>108.62</td>\n",
       "      <td>112.25</td>\n",
       "      <td>107.31</td>\n",
       "      <td>111.44</td>\n",
       "      <td>31006800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.153690</td>\n",
       "      <td>37.361920</td>\n",
       "      <td>35.717662</td>\n",
       "      <td>37.092315</td>\n",
       "      <td>62013600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close      Volume  Ex-Dividend  \\\n",
       "Date                                                                  \n",
       "2000-01-03  117.37  118.62  112.00  116.56  26614200.0          0.0   \n",
       "2000-01-04  113.56  117.12  112.25  112.62  27059500.0          0.0   \n",
       "2000-01-05  111.12  116.37  109.37  113.81  32029800.0          0.0   \n",
       "2000-01-06  112.19  113.87  108.37  110.00  27488300.0          0.0   \n",
       "2000-01-07  108.62  112.25  107.31  111.44  31006800.0          0.0   \n",
       "\n",
       "            Split Ratio  Adj. Open  Adj. High   Adj. Low  Adj. Close  \\\n",
       "Date                                                                   \n",
       "2000-01-03          1.0  39.066089  39.482146  37.278708   38.796484   \n",
       "2000-01-04          1.0  37.797947  38.982878  37.361920   37.485073   \n",
       "2000-01-05          1.0  36.985804  38.733244  36.403324   37.881159   \n",
       "2000-01-06          1.0  37.341949  37.901130  36.070479   36.613017   \n",
       "2000-01-07          1.0  36.153690  37.361920  35.717662   37.092315   \n",
       "\n",
       "            Adj. Volume  \n",
       "Date                     \n",
       "2000-01-03   53228400.0  \n",
       "2000-01-04   54119000.0  \n",
       "2000-01-05   64059600.0  \n",
       "2000-01-06   54976600.0  \n",
       "2000-01-07   62013600.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = data.iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Adj. Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-14</th>\n",
       "      <td>95.120</td>\n",
       "      <td>95.410</td>\n",
       "      <td>93.50</td>\n",
       "      <td>93.85</td>\n",
       "      <td>31576898.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.120</td>\n",
       "      <td>95.410</td>\n",
       "      <td>93.50</td>\n",
       "      <td>93.85</td>\n",
       "      <td>31576898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-15</th>\n",
       "      <td>93.530</td>\n",
       "      <td>94.580</td>\n",
       "      <td>92.83</td>\n",
       "      <td>94.18</td>\n",
       "      <td>26279014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.530</td>\n",
       "      <td>94.580</td>\n",
       "      <td>92.83</td>\n",
       "      <td>94.18</td>\n",
       "      <td>26279014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16</th>\n",
       "      <td>94.680</td>\n",
       "      <td>95.380</td>\n",
       "      <td>93.92</td>\n",
       "      <td>94.60</td>\n",
       "      <td>47329521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.680</td>\n",
       "      <td>95.380</td>\n",
       "      <td>93.92</td>\n",
       "      <td>94.60</td>\n",
       "      <td>47329521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-19</th>\n",
       "      <td>93.740</td>\n",
       "      <td>93.900</td>\n",
       "      <td>92.11</td>\n",
       "      <td>92.89</td>\n",
       "      <td>31752589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.740</td>\n",
       "      <td>93.900</td>\n",
       "      <td>92.11</td>\n",
       "      <td>92.89</td>\n",
       "      <td>31752589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-20</th>\n",
       "      <td>93.050</td>\n",
       "      <td>93.770</td>\n",
       "      <td>93.00</td>\n",
       "      <td>93.13</td>\n",
       "      <td>21787780.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.050</td>\n",
       "      <td>93.770</td>\n",
       "      <td>93.00</td>\n",
       "      <td>93.13</td>\n",
       "      <td>21787780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-21</th>\n",
       "      <td>92.930</td>\n",
       "      <td>94.050</td>\n",
       "      <td>92.21</td>\n",
       "      <td>92.48</td>\n",
       "      <td>23753263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.930</td>\n",
       "      <td>94.050</td>\n",
       "      <td>92.21</td>\n",
       "      <td>92.48</td>\n",
       "      <td>23753263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-22</th>\n",
       "      <td>91.265</td>\n",
       "      <td>91.750</td>\n",
       "      <td>89.66</td>\n",
       "      <td>89.79</td>\n",
       "      <td>37578166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.265</td>\n",
       "      <td>91.750</td>\n",
       "      <td>89.66</td>\n",
       "      <td>89.79</td>\n",
       "      <td>37578166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>89.500</td>\n",
       "      <td>90.460</td>\n",
       "      <td>87.08</td>\n",
       "      <td>87.18</td>\n",
       "      <td>42159397.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.500</td>\n",
       "      <td>90.460</td>\n",
       "      <td>87.08</td>\n",
       "      <td>87.18</td>\n",
       "      <td>42159397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>90.610</td>\n",
       "      <td>94.000</td>\n",
       "      <td>90.40</td>\n",
       "      <td>93.78</td>\n",
       "      <td>55031149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.610</td>\n",
       "      <td>94.000</td>\n",
       "      <td>90.40</td>\n",
       "      <td>93.78</td>\n",
       "      <td>55031149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27</th>\n",
       "      <td>94.940</td>\n",
       "      <td>95.139</td>\n",
       "      <td>88.51</td>\n",
       "      <td>89.47</td>\n",
       "      <td>53704562.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.940</td>\n",
       "      <td>95.139</td>\n",
       "      <td>88.51</td>\n",
       "      <td>89.47</td>\n",
       "      <td>53704562.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High    Low  Close      Volume  Ex-Dividend  \\\n",
       "Date                                                                \n",
       "2018-03-14  95.120  95.410  93.50  93.85  31576898.0          0.0   \n",
       "2018-03-15  93.530  94.580  92.83  94.18  26279014.0          0.0   \n",
       "2018-03-16  94.680  95.380  93.92  94.60  47329521.0          0.0   \n",
       "2018-03-19  93.740  93.900  92.11  92.89  31752589.0          0.0   \n",
       "2018-03-20  93.050  93.770  93.00  93.13  21787780.0          0.0   \n",
       "2018-03-21  92.930  94.050  92.21  92.48  23753263.0          0.0   \n",
       "2018-03-22  91.265  91.750  89.66  89.79  37578166.0          0.0   \n",
       "2018-03-23  89.500  90.460  87.08  87.18  42159397.0          0.0   \n",
       "2018-03-26  90.610  94.000  90.40  93.78  55031149.0          0.0   \n",
       "2018-03-27  94.940  95.139  88.51  89.47  53704562.0          0.0   \n",
       "\n",
       "            Split Ratio  Adj. Open  Adj. High  Adj. Low  Adj. Close  \\\n",
       "Date                                                                  \n",
       "2018-03-14          1.0     95.120     95.410     93.50       93.85   \n",
       "2018-03-15          1.0     93.530     94.580     92.83       94.18   \n",
       "2018-03-16          1.0     94.680     95.380     93.92       94.60   \n",
       "2018-03-19          1.0     93.740     93.900     92.11       92.89   \n",
       "2018-03-20          1.0     93.050     93.770     93.00       93.13   \n",
       "2018-03-21          1.0     92.930     94.050     92.21       92.48   \n",
       "2018-03-22          1.0     91.265     91.750     89.66       89.79   \n",
       "2018-03-23          1.0     89.500     90.460     87.08       87.18   \n",
       "2018-03-26          1.0     90.610     94.000     90.40       93.78   \n",
       "2018-03-27          1.0     94.940     95.139     88.51       89.47   \n",
       "\n",
       "            Adj. Volume  \n",
       "Date                     \n",
       "2018-03-14   31576898.0  \n",
       "2018-03-15   26279014.0  \n",
       "2018-03-16   47329521.0  \n",
       "2018-03-19   31752589.0  \n",
       "2018-03-20   21787780.0  \n",
       "2018-03-21   23753263.0  \n",
       "2018-03-22   37578166.0  \n",
       "2018-03-23   42159397.0  \n",
       "2018-03-26   55031149.0  \n",
       "2018-03-27   53704562.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.294468</td>\n",
       "      <td>0.898922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-15</th>\n",
       "      <td>0.717082</td>\n",
       "      <td>0.832323</td>\n",
       "      <td>0.840643</td>\n",
       "      <td>0.135102</td>\n",
       "      <td>0.943396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16</th>\n",
       "      <td>0.921708</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.768326</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-19</th>\n",
       "      <td>0.754448</td>\n",
       "      <td>0.694950</td>\n",
       "      <td>0.735380</td>\n",
       "      <td>0.299753</td>\n",
       "      <td>0.769542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-20</th>\n",
       "      <td>0.631673</td>\n",
       "      <td>0.668687</td>\n",
       "      <td>0.865497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-21</th>\n",
       "      <td>0.610320</td>\n",
       "      <td>0.725253</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.059124</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-22</th>\n",
       "      <td>0.314057</td>\n",
       "      <td>0.260606</td>\n",
       "      <td>0.377193</td>\n",
       "      <td>0.474994</td>\n",
       "      <td>0.351752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612802</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>0.197509</td>\n",
       "      <td>0.715151</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27</th>\n",
       "      <td>0.967972</td>\n",
       "      <td>0.945253</td>\n",
       "      <td>0.209064</td>\n",
       "      <td>0.960095</td>\n",
       "      <td>0.308625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low    Volume     Close\n",
       "Date                                                        \n",
       "2018-03-14  1.000000  1.000000  0.938596  0.294468  0.898922\n",
       "2018-03-15  0.717082  0.832323  0.840643  0.135102  0.943396\n",
       "2018-03-16  0.921708  0.993939  1.000000  0.768326  1.000000\n",
       "2018-03-19  0.754448  0.694950  0.735380  0.299753  0.769542\n",
       "2018-03-20  0.631673  0.668687  0.865497  0.000000  0.801887\n",
       "2018-03-21  0.610320  0.725253  0.750000  0.059124  0.714286\n",
       "2018-03-22  0.314057  0.260606  0.377193  0.474994  0.351752\n",
       "2018-03-23  0.000000  0.000000  0.000000  0.612802  0.000000\n",
       "2018-03-26  0.197509  0.715151  0.485380  1.000000  0.889488\n",
       "2018-03-27  0.967972  0.945253  0.209064  0.960095  0.308625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalise data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "cols = ['Open','High','Low','Volume','Close']\n",
    "#cols = ['Adj. Open','Adj. High','Adj. Low','Adj. Volume','Adj. Close']\n",
    "df = pandas.DataFrame(scaler.fit_transform(test_df[cols]) , columns=cols, index=test_df.index, dtype=\"float32\") #Normalize\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Test Dataset as pickle for later use\n",
    "# the test data in pkl format\n",
    "TEST_DATA = SHARE_ROOT + 'test_dataframe.pkl'\n",
    "df.to_pickle(TEST_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to recreate the feature engineering (creating the sequence features) just as we did in the model building notebook.\n",
    "\n",
    "We will do this within the webservice so that the service can take the raw  data, and return a scored result predicting the value (label).\n",
    "\n",
    "When scoreing an unseen observation, the model will not know the true labels. Therefore, we create a score_df without labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test init() and run() functions to read from the working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web service requires two functions, an init() function that will initialize the web service by loading the model into the service, and a run() function that will engineer the features to match the model call structure, and score that data set. We create the functions in here for testing and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    # read in the model file\n",
    "    from keras.models import model_from_json\n",
    "    global loaded_model\n",
    "    \n",
    "    # load json and create model\n",
    "    with open(LSTM_MODEL, 'r') as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(MODEL_WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(score_input): \n",
    "    amount_of_features = len(score_input.columns)\n",
    "    data = score_input.as_matrix() #converts to numpy\n",
    "    seq_len = 10\n",
    "    result = []\n",
    "    for index in range(len(data) - seq_len + 1):\n",
    "        result.append(data[index: index + seq_len + 1])\n",
    "        \n",
    "    result = np.array(result)\n",
    "    \n",
    "    seq_array = np.reshape(result, (result.shape[0], result.shape[1], amount_of_features))  \n",
    "    \n",
    "    print(seq_array.shape)\n",
    "        \n",
    "    try:\n",
    "        prediction = loaded_model.predict(seq_array)\n",
    "        pred = prediction.tolist()\n",
    "        return(pred)\n",
    "    except Exception as e:\n",
    "        return(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The webservice test requires an initialize of the webservice, then send the entire scoring data set into the model. We expect to get 1  prediction for each input in the scoring data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 5)\n",
      "[[0.572255551815033]]\n"
     ]
    }
   ],
   "source": [
    "init()\n",
    "pred=run(df)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we persist the assets we have created for use in operationalization. First we need to define the schema so the webservice knows what the payload data will look like as it comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input data frame\n",
    "inputs = {\"score_input\": SampleDefinition(DataTypes.PANDAS, df)}\n",
    "\n",
    "json_schema = generate_schema(run_func=run, inputs=inputs, filepath=SCHEMA_FILE)\n",
    "\n",
    "# save the schema file for deployment\n",
    "out = json.dumps(json_schema)\n",
    "with open(SCHEMA_FILE, 'w') as f:\n",
    "    f.write(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conda dependencies are defined in this webservices_conda.yaml file. This will be used to tell the webservice server which python packages are required to run this web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./stockdemo-model/webservices_conda.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SHARE_ROOT}webservices_conda.yaml\n",
    "\n",
    "# Conda environment specification. The dependencies defined in this file will\n",
    "# be automatically provisioned for managed runs. These include runs against\n",
    "# the localdocker, remotedocker, and cluster compute targets.\n",
    "\n",
    "# Note that this file is NOT used to automatically manage dependencies for the\n",
    "# local compute target. To provision these dependencies locally, run:\n",
    "# conda env update --file conda_dependencies.yml\n",
    "\n",
    "# Details about the Conda environment file format:\n",
    "# https://conda.io/docs/using/envs.html#create-environment-file-by-hand\n",
    "\n",
    "# For managing Spark packages and configuration, see spark_dependencies.yml.\n",
    "\n",
    "name: project_environment\n",
    "channels:\n",
    "- conda-forge\n",
    "- defaults\n",
    "dependencies:\n",
    "  - python=3.5.2\n",
    "  - pip:\n",
    "    - azure-common==1.1.8\n",
    "    - azure-storage==0.36.0\n",
    "    - numpy==1.14.0 \n",
    "    - sklearn\n",
    "    - keras\n",
    "    - tensorflow\n",
    "    - h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lstmscore.py file is python code defining the web service operation. It includes both the init() and run() functions defined earlier imports the required libraries. These should be nearly identical to the previous defined versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./stockdemo-model/lstmscore.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SHARE_ROOT}lstmscore.py\n",
    "\n",
    "# import the libraries\n",
    "import keras\n",
    "import tensorflow\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def init():\n",
    "    # read in the model file\n",
    "    from keras.models import model_from_json\n",
    "    global loaded_model\n",
    "    \n",
    "    # load json and create model\n",
    "    with open('modellstm.json', 'r') as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"modellstm.h5\")\n",
    "\n",
    "def run(score_input): \n",
    "    amount_of_features = len(score_input.columns)\n",
    "    data = score_input.as_matrix() #converts to numpy\n",
    "    seq_len = 10\n",
    "    result = []\n",
    "    for index in range(len(data) - seq_len + 1):\n",
    "        result.append(data[index: index + seq_len + 1])\n",
    "        \n",
    "    result = np.array(result)\n",
    "    \n",
    "    seq_array = np.reshape(result, (result.shape[0], result.shape[1], amount_of_features))  \n",
    "    \n",
    "    print(seq_array.shape)\n",
    "        \n",
    "    try:\n",
    "        prediction = loaded_model.predict(seq_array)\n",
    "        pred = prediction.tolist()\n",
    "        return(pred)\n",
    "    except Exception as e:\n",
    "        return(str(e))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    init()\n",
    "    run('[{\"Open\":0.7127071619,\"High\":0.7314814925,\"Low\":0.5424528122,\"Volume\":1.0,\"Close\":0.9403669834},{\"Open\":0.9337016344,\"High\":1.0,\"Low\":1.0,\"Volume\":0.4399125874,\"Close\":0.8715596199},{\"Open\":0.9226519465,\"High\":0.879629612,\"Low\":0.9858490825,\"Volume\":0.1769355834,\"Close\":1.0},{\"Open\":1.0,\"High\":0.805555582,\"Low\":0.6556603909,\"Volume\":0.354439944,\"Close\":0.770642221},{\"Open\":0.8674033284,\"High\":0.662037015,\"Low\":0.5613207817,\"Volume\":0.3036391139,\"Close\":0.43577981},{\"Open\":0.2486187816,\"High\":0.3240740597,\"Low\":0.4386792481,\"Volume\":0.1165050864,\"Close\":0.5275229216},{\"Open\":0.3038673997,\"High\":0.2037037015,\"Low\":0.0,\"Volume\":0.4684149027,\"Close\":0.0},{\"Open\":0.0718232021,\"High\":0.0,\"Low\":0.0330188684,\"Volume\":0.2322592139,\"Close\":0.0},{\"Open\":0.0055248621,\"High\":0.1666666716,\"Low\":0.1179245263,\"Volume\":0.2997646928,\"Close\":0.2706421912},{\"Open\":0.0,\"High\":0.0740740746,\"Low\":0.1839622706,\"Volume\":0.0,\"Close\":0.2798165083},{\"Open\":0.2209944725,\"High\":0.3356481493,\"Low\":0.4528301954,\"Volume\":0.2173066139,\"Close\":0.56422019}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also include a python file test_service.py which can test the web service you create. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./stockdemo-model/test_service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SHARE_ROOT}test_service.py\n",
    "\n",
    "import urllib\n",
    "import json \n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# The URL will need to be editted after service create.\n",
    "url = 'http://127.0.0.1:32773/score'\n",
    "\n",
    "## Sequence length will need to match the training sequence length from the model training\n",
    "sequence_length = 10\n",
    "\n",
    "# We'll read in this data to test the service\n",
    "body = pd.read_pickle('test_dataframe.pkl')\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "try:\n",
    "    if body.shape[0] < sequence_length : \n",
    "        print(\"Skipping scoring as we need {} records to score and only have {} records.\".format(sequence_length, body.shape[0]))\n",
    "    else:\n",
    "        #print('{}'.format(body.shape))\n",
    "        body = \"{\\\"score_input\\\": \" + \\\n",
    "                    body.to_json(orient=\"records\") +\\\n",
    "                    \"}\"\n",
    "        print (body + '\\n')\n",
    "        req = urllib.request.Request(url, str.encode(body), headers) \n",
    "\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            the_page = response.read()\n",
    "            print('{}'.format(the_page))\n",
    "        \n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code {}: \\n{}\".format(error, error.read))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.reason)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Docker on Linux\n",
    "\n",
    "> On a Linux DSVM, run the script below to configure Docker correctly. **Remember to log out and log back in after running the script.**\n",
    ">```\n",
    ">sudo /opt/microsoft/azureml/initial_setup.sh\n",
    ">``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a web service out of the scoring script\n",
    "\n",
    "Let's now see how we can create a scoring web service from the above model. There are multiple steps that go into doing this. We will be running commands from the command line, but we will also log into the Azure portal in order to see which resources are being created as we run various Azure CLI commands.\n",
    "\n",
    "### Register Azure Providers\n",
    "\n",
    "Enable the Azure Container Service and Azure Container Registry by making sure they are providers that are registered with your current subscription: \n",
    "\n",
    "```\n",
    "az provider register -n Microsoft.ContainerService\n",
    "az provider register -n Microsoft.ContainerRegistry\n",
    "```\n",
    "\n",
    "We can check the status of our registration by running:\n",
    "\n",
    "```\n",
    "az provider list --query \"[?contains(namespace,'Container')]\" -o table\n",
    "```\n",
    "\n",
    "`Microsoft.ContainerService` and `Microsoft.ContainerRegistry` should have `registrationState` of `Registered`.\n",
    "\n",
    "\n",
    "### Review and set your Model Management account\n",
    "\n",
    "You must have an Azure Machine Learning Model Management account in order to create a scoring service. Log into the Azure portal and find all the resources under your resource group. This should include Experimentation and a Model Management accounts.\n",
    "\n",
    "We can also list, show, and set model management accounts at the command line:\n",
    "\n",
    "```\n",
    "az ml account modelmanagement list -o table\n",
    "az ml account modelmanagement set -n <MODEL_MANAGEMENT_ACCOUNT> -g <RESOURCE_GROUP>\n",
    "az ml account modelmanagement show\n",
    "```\n",
    "\n",
    "If you do not have a model management account, you can create one from the command line with:\n",
    "\n",
    "```\n",
    "az ml account modelmanagement create -l <AZUREREGION> -n <NAME> -g <RESOURCE_GROUP>\n",
    "```\n",
    "\n",
    "Once you have set a model management account, we can create a compute environment.\n",
    "\n",
    "### Create a Compute Environment\n",
    "\n",
    "If we're doing this for the first time, then we need to set up an environment. We usually have a staging and a production environment. We can deploy our models to the staging environment to test them and then redeploy them to the production environment once we're happy with the result. To create a new environment run the following command after choosing a name for the staging environment. To use in production, we can provide the additional `--cluster` argument:\n",
    "\n",
    "```\n",
    "az ml env setup -l eastus2 -n <STAGING_ENVIRONMENT> -g <RESOURCE_GROUP>\n",
    "```\n",
    "\n",
    "We can look at all the environments under our subscription using `az ml env list -o table`. Creating the new environment takes about one minute, after which we can activate it and show it using this:\n",
    "\n",
    "```\n",
    "az ml env set -n <STAGING_ENVIRONMENT> -g <RESOURCE_GROUP>\n",
    "az ml env show\n",
    "\n",
    "```\n",
    "\n",
    "### Create the scoring service (local) \n",
    "\n",
    "Once we have the `env` and the model management account, we are ready to create the scoring service:\n",
    "\n",
    "These commands assume the current directory contains the webservice assets we created in throughout the notebooks in this scenario (at least `lstmscore.py`, `modellstm.json`, `modellstm.h5`, `service_schema.json` and `webservices_conda.yaml`). If not, in the AML CLI window, change to the directory where the zip file was unpacked. \n",
    "\n",
    "The command to create a web service (`<SERVICE_ID>`) with these operationalization assets in the current directory is:\n",
    "\n",
    "`\n",
    "az ml service create realtime -f <filename> -r <TARGET_RUNTIME> -m <MODEL_FILE> -s <SCHEMA_FILE> -n <SERVICE_ID>\n",
    "`\n",
    "For this example, we will call our webservice with the `SERVICE_ID` = `lstmwebservice`. The `SERVICE_ID` must be all lowercase, with no spaces. This command should work with your account and the deployment artifacts created in this notebook.\n",
    "\n",
    "`\n",
    "az ml service create realtime -f lstmscore.py -r python -m modellstm.json -m modellstm.h5 -s service_schema.json -c webservices_conda.yaml -n lstmwebservice\n",
    "`\n",
    "\n",
    "The `az ml service create` command does four distinct steps:\n",
    "\n",
    "1. It registers the model to facilitate versioning.\n",
    "2. It creates a manifest used to build a docker image.\n",
    "3. It builds a Docker image based on that manifest, and \n",
    "4. It initializes and runs that Docker image to provide the end-point for the prediction app. \n",
    "\n",
    "We can see these resources by going to the Azure portal and navigating to the Model Management resource, then click on **Model Management** in the blade of that resource.\n",
    "\n",
    "In the Model Management portal, we can view the resources that are created as the above command runs: the model, the manifest, the image, and the service. Click on each to view the resources.\n",
    "\n",
    "Note that we can see the model, the manifest and the image on the Azure portal, but we can't see the service we created. This is because we ran `az ml env setup ...` *without* the `--cluster` argument, which means the service was created locally. This can be useful for the purpose of testing the service as we develop our application. In a future lab, the same service will be deployed remotely to Azure Container Service and will be visible from the Azure portal.\n",
    "\n",
    "Return to the command line and test the service by running the example command given in the line `Usage for cmd: az ml service run realtime ...` which can be found in the output generated by the last command. This is not the most convenient way to test the service but it has the advantange of being done directly from the command line.\n",
    "\n",
    "### Test your deployment.\n",
    "\n",
    "Once complete, the `az ml service create` command returns sample usage commands to test the service for both PowerShell and the cmd prompt. You can copy and paste this command into the CLI to test the web service. However, since it is only an example with 2 rows/steps, we know the model can not return a reasonable score. Instead you will see the following error as detailed above:\n",
    "```\n",
    "{'Error': MlCliError({'Response Content': b'tuple index out of range',....\n",
    "\n",
    "```\n",
    "We have provided the `test_service.py` python script to send larger payloads to the service. First obtain the webservice endpoint with the following command. `az ml service usage realtime -i lstmwebservice`\n",
    "\n",
    "```\n",
    "> az ml service usage realtime -i lstmwebservice\n",
    "Scoring URL:\n",
    "    http://127.0.0.1:32770/score\n",
    "\n",
    "Headers:\n",
    "    Content-Type: application/json\n",
    "\n",
    "Swagger URL:\n",
    "    http://127.0.0.1:32770/swagger.json\n",
    "\n",
    "Sample CLI command:\n",
    "...\n",
    "```\n",
    "\n",
    "Copy the Scoring URL into the `url` variable in the `test_service.py` script and save the file.\n",
    "\n",
    "From the CLI, you can then run the script with the command and response similar to the following:\n",
    "\n",
    "`python test_service.py`\n",
    "\n",
    "You should see an output like this:\n",
    "```\n",
    "{\"score_input\": [{\"Open\":0.9337016344,\"High\":1.0,\"Low\":1.0,\"Volume\":0.9391515255,\"Close\":0.8715596199},{\"Open\":0.9226519465,\"High\":0.879629612,\"Low\":0.9858490825,\"Volume\":0.3777326047,\"Close\":1.0},{\"Open\":1.0,\"High\":0.805555582,\"Low\":0.6556603909,\"Volume\":0.7566794753,\"Close\":0.770642221},{\"Open\":0.8674033284,\"High\":0.662037015,\"Low\":0.5613207817,\"Volume\":0.6482268572,\"Close\":0.43577981},{\"Open\":0.2486187816,\"High\":0.3240740597,\"Low\":0.4386792481,\"Volume\":0.2487220019,\"Close\":0.5275229216},{\"Open\":0.3038673997,\"High\":0.2037037015,\"Low\":0.0,\"Volume\":1.0,\"Close\":0.0},{\"Open\":0.0718232021,\"High\":0.0,\"Low\":0.0330188684,\"Volume\":0.4958407879,\"Close\":0.0},{\"Open\":0.0055248621,\"High\":0.1666666716,\"Low\":0.1179245263,\"Volume\":0.639955461,\"Close\":0.2706421912},{\"Open\":0.0,\"High\":0.0740740746,\"Low\":0.1839622706,\"Volume\":0.0,\"Close\":0.2798165083},{\"Open\":0.2209944725,\"High\":0.3356481493,\"Low\":0.4528301954,\"Volume\":0.4639191031,\"Close\":0.56422019}]}\n",
    "\n",
    "b'[[0.26219600439071655]]'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Service to production\n",
    "\n",
    "In this section, we will recreate the service, but this time not as a local service but a remote service. To deploy the web service to a production environment, first set up the environment using the following command:\n",
    "\n",
    "```\n",
    "az ml env setup --cluster -n <ENVIRONMENT_NAME> -l <AZURE_REGION e.g. eastus2> [-g <RESOURCE_GROUP>]\n",
    "```\n",
    "\n",
    "Respond with no to the question about `Reuse storage and ACR (Y/n)?`. This sets up an AKS cluster with Kubernetes as the orchestrator. The cluster environment setup command creates the following resources in our subscription:\n",
    "\n",
    "1. A resource group (if not provided, or if the name provided does not exist)\n",
    "2. A storage account (use the existing one)\n",
    "3. An Azure Container Registry (ACR)\n",
    "4. A Kubernetes deployment on an Azure Container Service (AKS) cluster\n",
    "5. An Application insights account\n",
    "\n",
    "The resource group, storage account, and ACR are created quickly. The AKS deployment can take up to 20 minutes. We use the following command to check the status of an ongoing cluster provisioning:\n",
    "\n",
    "```\n",
    "az ml env show -n <ENVIRONMENT_NAME> -g <RESOURCE_GROUP>\n",
    "```\n",
    "\n",
    "If the deployment fails the first time and we get an error message saying `Resource quota limit exceeded.` then it means we are over the utilization limit for our subscription. In this case, we can go to the Azure portal and delete any resources we are not using, then delete the above cluster `az ml env delete --cluster <ENVIRONMENT_NAME> -g <RESOURCE_GROUP>`, and finally re-create the cluster using `az ml env setup...` as we did earlier.\n",
    "\n",
    "Ensure that `\"Provisioning State\"` changes from `\"Creating\"` to `\"Succeeded\"` before proceeding further. Once this is done, we can set the above environment as our compute environment:\n",
    "\n",
    "```\n",
    "az ml env set -n <ENVIRONMENT_NAME> -g <RESOURCE_GROUP>\n",
    "```\n",
    "\n",
    "To deploy the saved model as a web service, we execute the below command:\n",
    "`\n",
    "az ml service create realtime -f lstmscore.py -r python -m modellstm.json -m modellstm.h5 -s service_schema.json -c webservices_conda.yaml -n lstmwebservice\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above command provides us with a single step execution it helps to break it down into multiple steps to see what is happening in the background. We can see what the different steps are by just looking at the output generated by the above command. The first step consists of loading the trained model `model.pkl` into the Azure model registry. To look at available models in the model registry we can run the following command:\n",
    "\n",
    "```\n",
    "az ml model list -o table\n",
    "```\n",
    "\n",
    "Currently, our registered models are not tagged, making it hard to tell them apart. So we begin by re-registering the trained model and properly describing or tagging it.\n",
    "\n",
    "```\n",
    "az ml model register -m <MODEL_FILE> -n <MODEL_NAME> -d \"Any description\"\n",
    "```\n",
    "\n",
    "We can always check the details of registered models using the following commands:\n",
    "\n",
    "```\n",
    "az ml model show -m <MODEL_ID>\n",
    "```\n",
    "\n",
    "Once a model is created, the next step is to create a manifest from the model.\n",
    "\n",
    "```\n",
    "az ml manifest create -n <MANIFEST_NAME> -i <MODEL_ID> -r <RUN_TIME, e.g. python or spark-py> -f <SCORING_SCRIPT, e.g. score.py> -s <SCHEMA_FILE>\n",
    "```\n",
    "\n",
    "The above command makes it clear that a model manifest is just a trained model paired with a few dependencies so that it can run as a service. The dependencies are the model's run time, which right now is a choice between `python` and `spark-py`, the python script to execute the scoring, the Conda dependencies to control the python environment, and the schema file to use to check against the in-coming data.\n",
    "\n",
    "We can check that our manifest was created by running this:\n",
    "\n",
    "```\n",
    "az ml manifest show -i <MANIFEST_ID>\n",
    "```\n",
    "\n",
    "We have almost all it takes to create a service, but the system dependencies. As we covered this is a prior lab, the best way to handle system dependencies is by using Docker images. These Docker images can then be used to spin off containers that run the service. We can scale the service by spnning off more Docker containers out of the same image. The next command creates a Docker image out of the model manifest we created above.\n",
    "\n",
    "```\n",
    "az ml image create -n <IMAGE_NAME> --manifest-id <MANIFEST_ID>\n",
    "```\n",
    "\n",
    "Once again we can check our service but simply running the following command:\n",
    "\n",
    "```\n",
    "az ml image show -i <IMAGE_ID>\n",
    "```\n",
    "\n",
    "Finally, we are now ready to spin a Docker container to host our service.\n",
    "\n",
    "```\n",
    "az ml service create realtime -n <SERVICE_NAME> --image-id <IMAGE_ID>\n",
    "```\n",
    "\n",
    "That's it. We now have the remote service up and running. We can run some queries against the service using example commands shown in the output generated when we ran the last command. This sequence of commands make clear what the four sequetial steps are that go into creating a service from a model and how these steps tie local resources to the cloud via the Azure Model Management account:\n",
    "\n",
    "  - register the model\n",
    "  - create and register a model manifest\n",
    "  - create and register a Docker image\n",
    "  - spinn a container from the Docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional)  Update Service with new model\n",
    "\n",
    "To use a different model in the service, we can perform a simple update to the service. \n",
    "There are three steps to perform in order to update the service:\n",
    "\n",
    "We first register the new model, and we do so under the same name as the old model. This will NOT overwrite the old model. Instead it will create a new version of it, which we can tag using the `-t` and add a description using `-d` arguments.\n",
    "\n",
    "```\n",
    "az ml model register -m <MODEL_FILE> -n <MODEL_NAME> -d \"Any description\"\n",
    "```\n",
    "\n",
    "We can see the new model (along with other versions if we had previously registered models under the same name) by running\n",
    "\n",
    "```\n",
    "az ml model list -o table\n",
    "```\n",
    "\n",
    "We now create a manifest for the model in Azure Container Service. To do so, in the next command, we replace `<MODEL_ID>` with the model ID that was returned in the last command:\n",
    "\n",
    "```\n",
    "az ml manifest create -n <MANIFEST_NAME> -i <MODEL_ID> -r <RUN_TIME, e.g. python or spark-py> -f <SCORING_SCRIPT, e.g. score.py> -s <SCHEMA_FILE>\n",
    "```\n",
    "\n",
    "We now get the manifest ID when we run `az ml manifest create`. Make a note of this id and replace it in the below command when creating image.\n",
    "\n",
    "```\n",
    "az ml image create -n <IMAGE_NAME> --manifest-id <MANIFEST_ID>\n",
    "```\n",
    "\n",
    "Finally, the last step is to update the existing service out of the new image created. We would need the image ID created from the last step along with the service ID. To obtain the service id, we can run `az ml service list realtime` to get a list of all the service IDs, or we can look up the service on the Azure portal. Run the below command to update the service:\n",
    "\n",
    "```\n",
    "az ml service update realtime -i <SERVICE_ID> --image-id <NEW_IMAGE_ID>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete web service\n",
    "```\n",
    "az ml service delete realtime --id=<SERVICE_ID>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
